{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from spamassassin_client import SpamAssassin\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from util import run_sa, evaluate\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('spammy_words.txt', 'r') as f:\n",
    "    spammy_words = set(f.read().splitlines())\n",
    "len(list(spammy_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just default to getting first synset of word, ordered by popularity, wont guarantee correct usage in context but should be good enough\n",
    "# could use BERT in this way as well? \"A synonym for ___ is ___\" prompt?\n",
    "# get nex\n",
    "def replace_word(word):\n",
    "    try: \n",
    "        synset = wn.synsets(word)[0] # get most popular synset\n",
    "        lemmas = synset.lemmas()\n",
    "        for l in lemmas:\n",
    "            if word.lower() != l.name().lower():\n",
    "                return True, l.name().replace(\"_\", \" \")\n",
    "        return False, word\n",
    "    except:\n",
    "        return False, word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_word(word):\n",
    "    return \"..\".join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subj_body_tokens(header, body):\n",
    "    # managing header\n",
    "    header_spl = header.split(\"\\n\", 1)\n",
    "    subj = header_spl[0]\n",
    "    header_leftovers = header_spl[1]\n",
    "    # ----\n",
    "    subj_content = subj.split(\"Subject:\", 1)[1].strip()\n",
    "    body_content = body.strip()\n",
    "\n",
    "    subj_tokens = nltk.word_tokenize(subj_content)\n",
    "    body_tokens = nltk.word_tokenize(body_content)\n",
    "\n",
    "    return subj_tokens, body_tokens, header_leftovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconsruct_email(subj_tokens, header_leftovers, body_tokens):\n",
    "    header_str = \"Subject: \" + (TreebankWordDetokenizer().detokenize(subj_tokens).strip() + \"\\n\" + header_leftovers).strip()\n",
    "    body_str = TreebankWordDetokenizer().detokenize(body_tokens).strip()\n",
    "\n",
    "    return header_str + \"\\n\\n\" + body_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_replace_attack(email, fallback_poison=False):\n",
    "    spl = email.split(\"\\n\\n\", 1)\n",
    "    header, body = spl[0].strip(), spl[1].strip()\n",
    "    subj_tokens, body_tokens, header_leftovers = get_subj_body_tokens(header, body)\n",
    "\n",
    "    new_subj_tokens = []\n",
    "    new_body_tokens = []\n",
    "\n",
    "    num_potential = 0 # we know there is a spammy word here\n",
    "    num_successful = 0 # we replaced it with something\n",
    "    repl = [] # replacement information\n",
    "    \n",
    "    for s_t in subj_tokens:\n",
    "        w_new = s_t\n",
    "        if s_t in spammy_words:\n",
    "            num_potential += 1\n",
    "            success, new_word = replace_word(s_t)\n",
    "            w_new = new_word\n",
    "            if success:\n",
    "                num_successful += 1\n",
    "            elif fallback_poison: # poison word if we can not find a synonym\n",
    "                w_new = poison_word(s_t)\n",
    "            repl.append((s_t, w_new, success))\n",
    "        new_subj_tokens.append(w_new)\n",
    "            \n",
    "\n",
    "    for b_t in body_tokens:\n",
    "        w_new = b_t\n",
    "        if b_t in spammy_words:\n",
    "            num_potential += 1\n",
    "            success, new_word = replace_word(b_t)\n",
    "            w_new = new_word\n",
    "            if success:\n",
    "                num_successful += 1\n",
    "            elif fallback_poison: # poison word if we can not find a synonym\n",
    "                w_new = poison_word(b_t)\n",
    "            repl.append((b_t, w_new, success))\n",
    "        new_body_tokens.append(w_new)\n",
    "\n",
    "    new_email = reconsruct_email(new_subj_tokens, header_leftovers, new_body_tokens)\n",
    "    return num_potential, num_successful, repl, new_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisoning_attack(email):\n",
    "    spl = email.split(\"\\n\\n\", 1)\n",
    "    header, body = spl[0].strip(), spl[1].strip()\n",
    "    subj_tokens, body_tokens, header_leftovers = get_subj_body_tokens(header, body)\n",
    "\n",
    "    new_subj_tokens = []\n",
    "    new_body_tokens = []\n",
    "\n",
    "    num_replacements = 0 # we know there is a spammy word here\n",
    "    repl = [] # replacement information\n",
    "    \n",
    "    for s_t in subj_tokens:\n",
    "        w_new = s_t\n",
    "        if s_t in spammy_words:\n",
    "            w_new = poison_word(s_t)\n",
    "            num_replacements += 1\n",
    "            repl.append((s_t, w_new, True))\n",
    "        new_subj_tokens.append(w_new)\n",
    "            \n",
    "\n",
    "    for b_t in body_tokens:\n",
    "        w_new = b_t\n",
    "        if b_t in spammy_words:\n",
    "            w_new = poison_word(b_t)\n",
    "            num_replacements += 1\n",
    "            repl.append((b_t, w_new, True))\n",
    "        new_body_tokens.append(w_new)\n",
    "        \n",
    "    new_email = reconsruct_email(new_subj_tokens, header_leftovers, new_body_tokens)\n",
    "    return num_replacements, repl, new_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_spam_df = pd.read_csv('data/goodSpam/goodSpam.csv')\n",
    "good_spam_text = good_spam_df['text']\n",
    "good_spam_labels = good_spam_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing the attack\n",
    "syn_repl_att_ret = [synonym_replace_attack(t) for t in good_spam_text]\n",
    "poison_att_ret = [poisoning_attack(t) for t in good_spam_text]\n",
    "both_att_ret = [synonym_replace_attack(t, fallback_poison=True) for t in good_spam_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_repl_text = [t[3] for t in syn_repl_att_ret]\n",
    "poison_text = [t[2] for t in poison_att_ret]\n",
    "both_att_text = [t[3] for t in both_att_ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: yakubu lawal @ international trust bank plc.\n",
      "Message-ID: <GTUBE1.1010101@example.net>\n",
      "Date: Wed, 23 Jul 2003 23:30:00 +0200\n",
      "From: Sender <sender@example.net>\n",
      "To: Recipient <recipient@example.net>\n",
      "MIME-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "\n",
      "dr yakubu lawal, head, operations manager, international trust bank plc . plot 84 / 88, ajose adeogun street, victoria island, lagos Federal Republic of Nigeria . attention: confidential letterfirst, i must solicit your confidence in thistransaction, this is by virtue of its nature as beingutterly confidential and top s..e..c..r..e..t . though i knowthat a transaction of this magnitude will make any oneapprehensive and worried, but i am assuring you thatall will be well at the end of the transaction . for the purpose of introduction, i am dr yakubu lawal, head, operations manager, international trust bank plc, in charge of personal and corporate accountsabove us $5, 000, 000 . 00 (five million us dollar only). icame to know of you in my private search for areliable and reputable person to handle a veryconfidential transaction which involves the transferof a immense sum of m..o..n..e..y to a foreign account requiring maximum confidence . the proposition: a foreigner, late mr grahams peterson, an oilmerchant / contractor with the federal govenment ofnigeria, until his death three years ago in a ghastlyauto crash, banked with us here at international trustbank plc ., lagos, and had a closingbalance of usd $21 . 5 m (twenty - one million, five hundredthousand united states dollar only) which the banknow unquestionably expects to be claimed by any of hisavailable foreign next of kin or alternatively bedonated to a discredited trust fund for arms andammunition at a military war college here in Federal Republic of Nigeria . fervent valuable efforts are being made by the bank toget in touch with any of the peterson family orrelatives but all have proved to no avail . it isbecause of the perceived possibility of not going tobe able to locate any of late mr grahams peterson' snext of kin (he had no wife and children) that themanagement under the influence of our chairman, boardof directors, retire major general kalu uke kalu, that an arrangement for the fund to be declared \"unclaimable \"and then be subsequently donated to thetrust fund for arms and ammunition which will furtherenhance the course of war in africa and the world ingeneral . in order to avert this negative development, myselfand some of my trusted colleagues in the bank now seekfor your permission to have you stand as late mrgrahams peterson' s next of kin so that the fund, usd $21 . 5 m would be subsequently transferred and paidinto your bank account as the donee next of kin . all documents and proves to enable you get this fundhave been carefully worked out and we are assuring youa 100% risk free involvement . your share would be 30% of the total amount, 5% has been set aside for expenseswhile the rest would be for myself and my colleaguesfor investment purposes in your company or any countryof your choice where the returns on investment will beoptimal . if this proposal is acceptable to you and you do notwish to take advantage of the trust we hope to bestowon you and your company, then kindly get to meimmediately via my e - mail furnishing me with: 1 . the names you want to use for this transaction . 2 . your contact address 3 . your most confidential telephone number 4 . fax number 5 . scoop e - mail so that i can forward to you therelevant details of this transaction . thank you in advance for your anticipatedco - operation . regards, dr yakubu lawal, international trust bank plc walla! mail - get your free lg mail today\n"
     ]
    }
   ],
   "source": [
    "print(both_att_text[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       160\n",
      "\n",
      "    accuracy                           1.00       160\n",
      "   macro avg       1.00      1.00      1.00       160\n",
      "weighted avg       1.00      1.00      1.00       160\n",
      "\n",
      "[[160]]\n",
      "AVG Score: 5.527500000000001\n"
     ]
    }
   ],
   "source": [
    "# evaluate baseline\n",
    "_, pred, scores = evaluate(zip(good_spam_text, good_spam_labels))\n",
    "# get avg score\n",
    "print(f'AVG Score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.83      0.91       268\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.50      0.41      0.45       268\n",
      "weighted avg       1.00      0.83      0.91       268\n",
      "\n",
      "[[  0   0]\n",
      " [ 46 222]]\n",
      "AVG Score: 4.9619402985074625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickhansen/miniconda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nickhansen/miniconda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nickhansen/miniconda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate poison\n",
    "_, pred, scores = evaluate(zip(poison_text, good_spam_labels))\n",
    "print(f'AVG Score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.82      0.90       268\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.50      0.41      0.45       268\n",
      "weighted avg       1.00      0.82      0.90       268\n",
      "\n",
      "[[  0   0]\n",
      " [ 48 220]]\n",
      "AVG Score: 5.068283582089553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickhansen/miniconda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nickhansen/miniconda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nickhansen/miniconda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate synonym replacement\n",
    "_, pred, scores = evaluate(zip(syn_repl_text, good_spam_labels))\n",
    "print(f'AVG Score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.80      0.89       268\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.50      0.40      0.45       268\n",
      "weighted avg       1.00      0.80      0.89       268\n",
      "\n",
      "[[  0   0]\n",
      " [ 53 215]]\n",
      "AVG Score: 4.888059701492537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickhansen/miniconda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nickhansen/miniconda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nickhansen/miniconda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate synonym replacement and poisoning fallback\n",
    "_, pred, scores = evaluate(zip(both_att_text, good_spam_labels))\n",
    "print(f'AVG Score: {np.mean(scores)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
