{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nickhansen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from spamassassin_client import SpamAssassin\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 label                                               text  \\\n",
      "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
      "7        4185  spam  Subject: looking for medication ? we ` re the ...   \n",
      "\n",
      "   label_num  \n",
      "3          1  \n",
      "7          1  \n",
      "   Unnamed: 0 label                                               text  \\\n",
      "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
      "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
      "\n",
      "   label_num  \n",
      "0          0  \n",
      "1          0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/spam_ham_dataset.csv')\n",
    "spam = df[df['label'] == 'spam']\n",
    "ham = df[df['label'] == 'ham']\n",
    "print(spam.head(2))\n",
    "print(ham.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1499, 3672)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_text = spam['text'].values\n",
    "ham_text = ham['text'].values\n",
    "len(spam_text), len(ham_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Subject: finding email addresses : advice\\n \\n there seem to be pretty frequent requests for email addresses on the linguist list . people with unix accounts can use the \" finger \" command to look up addresses - - if they know the name and affiliation of the person they \\' re looking for ( others may have access to some sort of finger utility ) . for example , there was a recent request for the internet address of someone whose bitnet address is escatton @ albnyvms here \\'s how i used finger to find his internet address : finger escatton @ albnyvms finger : albnyvms : unknown host finger escatton @ albnyvms . edu finger : albnyvms . edu : unknown host well , albnyvms does n\\'t sound very internet-like , so let \\'s start guessing : finger scatton @ albany . edu [ albany . edu ] ( there is no account scatton on this node . ) name : ernest scatton title : professor , german and slavic languages + literat address : humanities 246 university at albany 1400 washington av albany ny 12222-0001 phone : + 1 518-442 - 4224 bitnet : escatton @ albnyvms internet : escatton @ cnsvax . albany . edu there it is . if you have less information - - for example , you know the person is somewhere in new york state , but not where exactly - - you can use one of the \" white pages \" services available . a good starting point is : http : / / home . netscape . com / commun / internet _ white _ pages . html happy hunting !\\n',\n",
       "  'ham'),\n",
       " ('Subject: q : \\' this \\' and \\' that \\'\\n \\n dear linguists : some present-day \\' european \\' languages have only one set of simple demonstratives and the opposition of < this > vs . < that > is expressed by the help of < here > and < there > : french ceci \\' this \\' ce livre-ci \\' this book \\' cela \\' that \\' ce livre-l ` a \\' that book \\' swedish det ha \" r \\' this \\' den ha \" r bilen \\' this car \\' det da \" r \\' that \\' den da \" r bilen \\' that car \\' estonian see siin \\' this \\' see maja siin \\' this house \\' see seal \\' that \\' see maja seal \\' that house \\' my sweidish - german dictionary ( stora tyska ordboken ) gives < der hier > and < der da > as colloquial ( familia \" r , umgangssprachlich ) german forms which conrrespond to < den ha \" r > and < den da \" r > , respectively . how common is a demonstrative system like this ? incidentally , japanese has a rather sophisticated three-way distinction here : kono hon \\' this book ( you see here ) \\' sono hon \\' that book ( you see there ) , the book ( under discussion ) \\' ano hon \\' that book ( you see over there ) \\' so i \\' m afraid i will have to convince my students that the japanese are extravagant even in the way of using demonstratives . kazuto matsumura kazuto matsumura kmatsum @ tooyoo . l . u-tokyo . ac . jp - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - institute for cross - cultural studies ( tooyoo gengo ) faculty of letters , university of tokyo hongo 7 - 3 - 1 , bunkyo - ku , tokyo 113 japan tel . + 81 - 3-5800 - 3754 fax : + 81 - 3-5800 - 3740 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\\n',\n",
       "  'ham')]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_ds = [(text, 'spam') for text in spam_text]\n",
    "ham_ds = [(text, 'ham') for text in ham_text]\n",
    "combined_ds = spam_ds + ham_ds\n",
    "\n",
    "import random\n",
    "random.shuffle(combined_ds)\n",
    "\n",
    "combined_ds[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "vocab = set()\n",
    "for text, label in combined_ds:\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        w_l = word.lower()\n",
    "        if w_l.isalpha():\n",
    "            vocab.add(w_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(text):\n",
    "    rec_words = [w.lower() for w in nltk.word_tokenize(text)]\n",
    "    features = {}\n",
    "    for w in rec_words:\n",
    "        if w in vocab:\n",
    "            features[w] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3448, 1723)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = [(get_features(text), label) for text, label in combined_ds]\n",
    "splitPoint = len(combined) // 3\n",
    "train, test = combined[splitPoint:], combined[:splitPoint]\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.93905977945444\n"
     ]
    }
   ],
   "source": [
    "# NLTK's built-in implementation of the Naive Bayes classifier is trained\n",
    "classifier = nltk.NaiveBayesClassifier.train(train)\n",
    "\n",
    "# now, it is tested on the test set and the accuracy reported\n",
    "print(\"Accuracy: \", nltk.classify.accuracy(classifier, test)) #nltk.classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features_in_list(classifier, n=10):\n",
    "    \"\"\"\n",
    "    Return a nested list of the \"most informative\" features \n",
    "    used by the classifier along with it's predominant labels\n",
    "    \"\"\"\n",
    "    cpdist = classifier._feature_probdist       # probability distribution for feature values given labels\n",
    "    feature_list = []\n",
    "    for (fname, fval) in classifier.most_informative_features(n):\n",
    "        def labelprob(l):\n",
    "            return cpdist[l, fname].prob(fval)\n",
    "        labels = sorted([l for l in classifier._labels if fval in cpdist[l, fname].samples()], \n",
    "                        key=labelprob)\n",
    "        feature_list.append([fname, labels[-1]])\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_features = [x for x in show_most_informative_features_in_list(classifier, n=500) if x[1] == 'spam']\n",
    "len(spam_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['prescription', 'spam'],\n",
       " ['pain', 'spam'],\n",
       " ['stocks', 'spam'],\n",
       " ['sex', 'spam'],\n",
       " ['spam', 'spam'],\n",
       " ['popular', 'spam'],\n",
       " ['creative', 'spam'],\n",
       " ['advisor', 'spam'],\n",
       " ['adobe', 'spam'],\n",
       " ['conflict', 'spam'],\n",
       " ['ibm', 'spam'],\n",
       " ['unique', 'spam'],\n",
       " ['congress', 'spam'],\n",
       " ['deciding', 'spam'],\n",
       " ['pertaining', 'spam'],\n",
       " ['epson', 'spam'],\n",
       " ['sexual', 'spam'],\n",
       " ['sony', 'spam'],\n",
       " ['complaints', 'spam'],\n",
       " ['foresee', 'spam'],\n",
       " ['cheap', 'spam'],\n",
       " ['super', 'spam'],\n",
       " ['cisco', 'spam'],\n",
       " ['draw', 'spam'],\n",
       " ['target', 'spam'],\n",
       " ['generic', 'spam'],\n",
       " ['publisher', 'spam'],\n",
       " ['symbol', 'spam'],\n",
       " ['health', 'spam'],\n",
       " ['advises', 'spam'],\n",
       " ['beliefs', 'spam'],\n",
       " ['doctors', 'spam'],\n",
       " ['risks', 'spam'],\n",
       " ['ad', 'spam'],\n",
       " ['affordable', 'spam'],\n",
       " ['proven', 'spam'],\n",
       " ['shareholder', 'spam'],\n",
       " ['advanced', 'spam'],\n",
       " ['anxiety', 'spam'],\n",
       " ['shares', 'spam'],\n",
       " ['ali', 'spam'],\n",
       " ['solicitation', 'spam'],\n",
       " ['women', 'spam'],\n",
       " ['charset', 'spam'],\n",
       " ['effects', 'spam'],\n",
       " ['mix', 'spam'],\n",
       " ['penny', 'spam'],\n",
       " ['powerful', 'spam'],\n",
       " ['premiere', 'spam'],\n",
       " ['wi', 'spam'],\n",
       " ['investment', 'spam'],\n",
       " ['assumptions', 'spam'],\n",
       " ['consultation', 'spam'],\n",
       " ['girls', 'spam'],\n",
       " ['inches', 'spam'],\n",
       " ['movies', 'spam'],\n",
       " ['investing', 'spam'],\n",
       " ['body', 'spam'],\n",
       " ['adult', 'spam'],\n",
       " ['aggressive', 'spam'],\n",
       " ['emerging', 'spam'],\n",
       " ['massive', 'spam'],\n",
       " ['multi', 'spam'],\n",
       " ['thousand', 'spam'],\n",
       " ['videos', 'spam'],\n",
       " ['actions', 'spam'],\n",
       " ['anti', 'spam'],\n",
       " ['clearance', 'spam'],\n",
       " ['q', 'spam'],\n",
       " ['act', 'spam'],\n",
       " ['newsletter', 'spam'],\n",
       " ['cs', 'spam'],\n",
       " ['understands', 'spam'],\n",
       " ['affiliated', 'spam'],\n",
       " ['compared', 'spam'],\n",
       " ['fat', 'spam'],\n",
       " ['sources', 'spam'],\n",
       " ['microsoft', 'spam'],\n",
       " ['cap', 'spam'],\n",
       " ['thousands', 'spam'],\n",
       " ['africa', 'spam'],\n",
       " ['consumers', 'spam'],\n",
       " ['earning', 'spam'],\n",
       " ['examples', 'spam'],\n",
       " ['growing', 'spam'],\n",
       " ['opt', 'spam'],\n",
       " ['unlimited', 'spam'],\n",
       " ['woman', 'spam'],\n",
       " ['publication', 'spam'],\n",
       " ['professional', 'spam'],\n",
       " ['men', 'spam'],\n",
       " ['compliance', 'spam'],\n",
       " ['acquire', 'spam'],\n",
       " ['acts', 'spam'],\n",
       " ['beauty', 'spam'],\n",
       " ['bigger', 'spam'],\n",
       " ['border', 'spam'],\n",
       " ['expert', 'spam'],\n",
       " ['factual', 'spam'],\n",
       " ['formula', 'spam'],\n",
       " ['improved', 'spam'],\n",
       " ['litigation', 'spam'],\n",
       " ['overnight', 'spam'],\n",
       " ['rm', 'spam'],\n",
       " ['satisfied', 'spam'],\n",
       " ['tons', 'spam'],\n",
       " ['anticipated', 'spam'],\n",
       " ['broker', 'spam'],\n",
       " ['acrobat', 'spam'],\n",
       " ['brand', 'spam'],\n",
       " ['conclusion', 'spam'],\n",
       " ['husband', 'spam'],\n",
       " ['impossible', 'spam'],\n",
       " ['liquidation', 'spam'],\n",
       " ['produce', 'spam'],\n",
       " ['protocol', 'spam'],\n",
       " ['smart', 'spam'],\n",
       " ['watches', 'spam'],\n",
       " ['br', 'spam'],\n",
       " ['fund', 'spam'],\n",
       " ['reliance', 'spam'],\n",
       " ['exclusive', 'spam'],\n",
       " ['investors', 'spam'],\n",
       " ['understood', 'spam'],\n",
       " ['hot', 'spam'],\n",
       " ['plain', 'spam'],\n",
       " ['gotten', 'spam'],\n",
       " ['trademarks', 'spam'],\n",
       " ['titles', 'spam'],\n",
       " ['aa', 'spam'],\n",
       " ['advertising', 'spam'],\n",
       " ['brands', 'spam'],\n",
       " ['ci', 'spam'],\n",
       " ['deposit', 'spam'],\n",
       " ['ease', 'spam'],\n",
       " ['judge', 'spam'],\n",
       " ['lo', 'spam'],\n",
       " ['nv', 'spam'],\n",
       " ['recommended', 'spam'],\n",
       " ['seeking', 'spam'],\n",
       " ['servers', 'spam'],\n",
       " ['usb', 'spam'],\n",
       " ['war', 'spam'],\n",
       " ['wil', 'spam'],\n",
       " ['securities', 'spam'],\n",
       " ['doctor', 'spam'],\n",
       " ['advertisement', 'spam'],\n",
       " ['filings', 'spam'],\n",
       " ['mailings', 'spam'],\n",
       " ['wide', 'spam'],\n",
       " ['results', 'spam'],\n",
       " ['accordance', 'spam'],\n",
       " ['ascii', 'spam'],\n",
       " ['banking', 'spam'],\n",
       " ['bye', 'spam'],\n",
       " ['campaign', 'spam'],\n",
       " ['edition', 'spam'],\n",
       " ['english', 'spam'],\n",
       " ['girl', 'spam'],\n",
       " ['hosting', 'spam'],\n",
       " ['micro', 'spam'],\n",
       " ['onto', 'spam'],\n",
       " ['overseas', 'spam'],\n",
       " ['physicians', 'spam'],\n",
       " ['positioned', 'spam'],\n",
       " ['reliable', 'spam'],\n",
       " ['secured', 'spam'],\n",
       " ['serious', 'spam'],\n",
       " ['sp', 'spam'],\n",
       " ['teach', 'spam'],\n",
       " ['wife', 'spam'],\n",
       " ['wild', 'spam'],\n",
       " ['windows', 'spam'],\n",
       " ['digital', 'spam'],\n",
       " ['licensed', 'spam'],\n",
       " ['html', 'spam'],\n",
       " ['norton', 'spam'],\n",
       " ['sum', 'spam'],\n",
       " ['duty', 'spam'],\n",
       " ['seek', 'spam'],\n",
       " ['ads', 'spam'],\n",
       " ['appointment', 'spam'],\n",
       " ['brother', 'spam'],\n",
       " ['cards', 'spam'],\n",
       " ['certified', 'spam'],\n",
       " ['fear', 'spam'],\n",
       " ['ff', 'spam'],\n",
       " ['ia', 'spam'],\n",
       " ['indicating', 'spam'],\n",
       " ['military', 'spam'],\n",
       " ['mobile', 'spam'],\n",
       " ['movie', 'spam'],\n",
       " ['pics', 'spam'],\n",
       " ['pink', 'spam'],\n",
       " ['prospects', 'spam'],\n",
       " ['rem', 'spam'],\n",
       " ['santa', 'spam'],\n",
       " ['suspension', 'spam'],\n",
       " ['announces', 'spam'],\n",
       " ['tr', 'spam'],\n",
       " ['uk', 'spam'],\n",
       " ['children', 'spam'],\n",
       " ['invest', 'spam'],\n",
       " ['loading', 'spam'],\n",
       " ['believes', 'spam'],\n",
       " ['tabs', 'spam'],\n",
       " ['known', 'spam'],\n",
       " ['exactly', 'spam'],\n",
       " ['international', 'spam'],\n",
       " ['medical', 'spam'],\n",
       " ['mg', 'spam'],\n",
       " ['proprietary', 'spam'],\n",
       " ['revenues', 'spam'],\n",
       " ['visits', 'spam'],\n",
       " ['audience', 'spam'],\n",
       " ['complimentary', 'spam'],\n",
       " ['condition', 'spam'],\n",
       " ['consult', 'spam'],\n",
       " ['disclaimer', 'spam'],\n",
       " ['discover', 'spam'],\n",
       " ['drink', 'spam'],\n",
       " ['encoding', 'spam'],\n",
       " ['explosion', 'spam'],\n",
       " ['healthy', 'spam'],\n",
       " ['hidden', 'spam'],\n",
       " ['hurt', 'spam'],\n",
       " ['israel', 'spam'],\n",
       " ['loan', 'spam'],\n",
       " ['models', 'spam'],\n",
       " ['mrs', 'spam'],\n",
       " ['networking', 'spam'],\n",
       " ['notifications', 'spam'],\n",
       " ['pi', 'spam'],\n",
       " ['presence', 'spam'],\n",
       " ['qualified', 'spam'],\n",
       " ['raw', 'spam'],\n",
       " ['signing', 'spam'],\n",
       " ['strive', 'spam'],\n",
       " ['yard', 'spam'],\n",
       " ['size', 'spam'],\n",
       " ['contents', 'spam'],\n",
       " ['huge', 'spam'],\n",
       " ['z', 'spam'],\n",
       " ['accuracy', 'spam'],\n",
       " ['investor', 'spam'],\n",
       " ['convenient', 'spam'],\n",
       " ['drinks', 'spam'],\n",
       " ['negotiations', 'spam'],\n",
       " ['otc', 'spam'],\n",
       " ['somehow', 'spam'],\n",
       " ['guarantee', 'spam'],\n",
       " ['design', 'spam'],\n",
       " ['financing', 'spam'],\n",
       " ['grow', 'spam'],\n",
       " ['highest', 'spam'],\n",
       " ['lowest', 'spam'],\n",
       " ['ordering', 'spam'],\n",
       " ['simple', 'spam'],\n",
       " ['treatment', 'spam'],\n",
       " ['presently', 'spam'],\n",
       " ['age', 'spam'],\n",
       " ['achieve', 'spam'],\n",
       " ['antivirus', 'spam'],\n",
       " ['anybody', 'spam'],\n",
       " ['audio', 'spam'],\n",
       " ['beautiful', 'spam'],\n",
       " ['becoming', 'spam'],\n",
       " ['cancer', 'spam'],\n",
       " ['clock', 'spam'],\n",
       " ['cnn', 'spam'],\n",
       " ['dvds', 'spam'],\n",
       " ['eight', 'spam'],\n",
       " ['enterprise', 'spam'],\n",
       " ['expansion', 'spam'],\n",
       " ['fit', 'spam'],\n",
       " ['float', 'spam'],\n",
       " ['gen', 'spam'],\n",
       " ['highly', 'spam'],\n",
       " ['holds', 'spam'],\n",
       " ['hottest', 'spam'],\n",
       " ['images', 'spam'],\n",
       " ['involving', 'spam'],\n",
       " ['le', 'spam'],\n",
       " ['masters', 'spam'],\n",
       " ['mit', 'spam'],\n",
       " ['mortgage', 'spam'],\n",
       " ['mouth', 'spam'],\n",
       " ['profits', 'spam'],\n",
       " ['satisfaction', 'spam'],\n",
       " ['scroll', 'spam'],\n",
       " ['sharp', 'spam'],\n",
       " ['song', 'spam'],\n",
       " ['stronger', 'spam'],\n",
       " ['style', 'spam'],\n",
       " ['targeted', 'spam'],\n",
       " ['tired', 'spam'],\n",
       " ['ultimate', 'spam'],\n",
       " ['video', 'spam'],\n",
       " ['water', 'spam'],\n",
       " ['websites', 'spam'],\n",
       " ['wireless', 'spam'],\n",
       " ['worldwide', 'spam'],\n",
       " ['yourself', 'spam'],\n",
       " ['involve', 'spam'],\n",
       " ['software', 'spam'],\n",
       " ['v', 'spam'],\n",
       " ['ca', 'spam'],\n",
       " ['expectations', 'spam'],\n",
       " ['projects', 'spam'],\n",
       " ['alert', 'spam'],\n",
       " ['facts', 'spam'],\n",
       " ['blank', 'spam'],\n",
       " ['compensation', 'spam'],\n",
       " ['press', 'spam'],\n",
       " ['title', 'spam'],\n",
       " ['compare', 'spam'],\n",
       " ['holdings', 'spam'],\n",
       " ['dell', 'spam'],\n",
       " ['shall', 'spam'],\n",
       " ['advice', 'spam'],\n",
       " ['industry', 'spam'],\n",
       " ['man', 'spam'],\n",
       " ['compaq', 'spam'],\n",
       " ['absolutely', 'spam'],\n",
       " ['constitute', 'spam'],\n",
       " ['death', 'spam'],\n",
       " ['enhanced', 'spam'],\n",
       " ['instant', 'spam'],\n",
       " ['qualify', 'spam'],\n",
       " ['quit', 'spam'],\n",
       " ['registered', 'spam'],\n",
       " ['relief', 'spam'],\n",
       " ['lose', 'spam'],\n",
       " ['stop', 'spam'],\n",
       " ['meaning', 'spam'],\n",
       " ['perfect', 'spam'],\n",
       " ['technologies', 'spam'],\n",
       " ['amazing', 'spam'],\n",
       " ['dr', 'spam'],\n",
       " ['foreign', 'spam'],\n",
       " ['photos', 'spam'],\n",
       " ['thorough', 'spam'],\n",
       " ['vegas', 'spam'],\n",
       " ['events', 'spam'],\n",
       " ['hello', 'spam'],\n",
       " ['accepting', 'spam'],\n",
       " ['became', 'spam'],\n",
       " ['believed', 'spam'],\n",
       " ['bl', 'spam'],\n",
       " ['bold', 'spam'],\n",
       " ['borland', 'spam'],\n",
       " ['carrier', 'spam'],\n",
       " ['compatible', 'spam'],\n",
       " ['components', 'spam'],\n",
       " ['consumption', 'spam'],\n",
       " ['defense', 'spam'],\n",
       " ['die', 'spam'],\n",
       " ['disk', 'spam'],\n",
       " ['esteem', 'spam'],\n",
       " ['fancy', 'spam'],\n",
       " ['gold', 'spam'],\n",
       " ['grass', 'spam'],\n",
       " ['identity', 'spam'],\n",
       " ['inexpensive', 'spam'],\n",
       " ['integrated', 'spam'],\n",
       " ['min', 'spam'],\n",
       " ['mp', 'spam'],\n",
       " ['noting', 'spam'],\n",
       " ['origin', 'spam'],\n",
       " ['ou', 'spam'],\n",
       " ['papers', 'spam'],\n",
       " ['picks', 'spam'],\n",
       " ['programming', 'spam'],\n",
       " ['rank', 'spam'],\n",
       " ['sizes', 'spam'],\n",
       " ['som', 'spam'],\n",
       " ['surprised', 'spam'],\n",
       " ['swiss', 'spam'],\n",
       " ['trace', 'spam'],\n",
       " ['transferring', 'spam'],\n",
       " ['vancouver', 'spam'],\n",
       " ['versions', 'spam'],\n",
       " ['vest', 'spam'],\n",
       " ['winners', 'spam'],\n",
       " ['workspace', 'spam'],\n",
       " ['offering', 'spam'],\n",
       " ['watch', 'spam'],\n",
       " ['rock', 'spam'],\n",
       " ['million', 'spam'],\n",
       " ['friend', 'spam'],\n",
       " ['words', 'spam'],\n",
       " ['channels', 'spam'],\n",
       " ['consulting', 'spam'],\n",
       " ['daughter', 'spam'],\n",
       " ['dont', 'spam'],\n",
       " ['food', 'spam'],\n",
       " ['interpretation', 'spam'],\n",
       " ['lucky', 'spam'],\n",
       " ['nine', 'spam'],\n",
       " ['trial', 'spam'],\n",
       " ['usd', 'spam'],\n",
       " ['door', 'spam'],\n",
       " ['easy', 'spam'],\n",
       " ['contains', 'spam'],\n",
       " ['cable', 'spam'],\n",
       " ['category', 'spam'],\n",
       " ['european', 'spam'],\n",
       " ['forever', 'spam'],\n",
       " ['millions', 'spam'],\n",
       " ['pack', 'spam'],\n",
       " ['diligence', 'spam'],\n",
       " ['entertainment', 'spam'],\n",
       " ['designed', 'spam'],\n",
       " ['resulting', 'spam'],\n",
       " ['dollars', 'spam'],\n",
       " ['stock', 'spam'],\n",
       " ['heart', 'spam']]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_freqs = get_word_freqs(spam_text)\n",
    "# total_spam = sum(spam_freqs.values())\n",
    "ham_freqs = get_word_freqs(ham_text)\n",
    "# total_ham = sum(ham_freqs.values())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('?', '?'), 2386), ((':', '/'), 749), (('/', '/'), 747), (('http', ':'), 725), (('=', '3'), 462), (('.', '00'), 455), (('www', '.'), 411), (('nbsp', ';'), 378), (('=', 'http'), 333), (('com', '/'), 317), (('width', '='), 304), (('/', 'www'), 299), (('height', '='), 296), (('the', 'company'), 285), ((';', 'nbsp'), 285)]\n"
     ]
    }
   ],
   "source": [
    "spam_bigram_freqs = get_bigram_freqs(spam_text)\n",
    "ham_bigram_freqs = get_bigram_freqs(ham_text)\n",
    "spam_bigram_freqs.subtract(ham_bigram_freqs)\n",
    "print(spam_bigram_freqs.most_common(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = {k: v - (ham_freqs.get(k, 0)) for k, v in spam_freqs.items()}\n",
    "most_spammy_words = sorted(diff.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: A CRY FOR HELP\n",
      "Message-ID: <GTUBE1.1010101@example.net>\n",
      "Date: Wed, 23 Jul 2003 23:30:00 +0200\n",
      "From: Sender <sender@example.net>\n",
      "To: Recipient <recipient@example.net>\n",
      "Precedence: junk\n",
      "MIME-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "\n",
      "DEAR FRIEND, I AM MRS. SESE-SEKO WIDOW OF LATE PRESIDENT MOBUTU SESE-SEKO OF ZAIRE? NOW KNOWN AS DEMOCRATIC REPUBLIC OF CONGO (DRC). I AM MOVED TO WRITE YOU THIS LETTER, THIS WAS IN CONFIDENCE CONSIDERING MY PRESENTCIRCUMSTANCE AND SITUATION . I ESCAPED ALONG WITH MY HUSBAND AND TWO OF OUR SONS GEORGE KONGOLO AND BASHER OUT OF DEMOCRATIC REPUBLIC OF CONGO (DRC) TO ABIDJAN, COTE D'IVOIRE WHERE MY FAMILY AND I SETTLED, WHILE WE LATER MOVED TO SETTLED IN MORROCO WHERE MY HUSBAND LATER DIED OF CANCER DISEASE . HOWEVER DUE TO THIS SITUATION WE DECIDED TO CHANGED MOST OF MY HUSBAND'S BILLIONS OF DOLLARS DEPOSITED IN SWISS BANK AND OTHER COUNTRIES INTO OTHER FORMS OF MONEY CODED FOR SAFE PURPOSE BECAUSE THE NEW HEAD OF STATE OF (DR) MR LAURENT KABILA HAS MADE ARRANGEMENT WITH THE SWISS GOVERNMENT AND OTHER EUROPEAN COUNTRIES TO FREEZE ALL MY LATE HUSBAND'S TREASURES DEPOSITED IN SOME EUROPEAN COUNTRIES . HENCE MY CHILDREN AND I DECIDED LAYING LOW IN AFRICA TO STUDY THE SITUATION TILL WHEN THINGS GETS BETTER, LIKE NOW THAT PRESIDENT KABILA IS DEAD AND THE SON TAKING OVER (JOSEPH KABILA). ONE OF MY LATE HUSBAND'S CHATEAUX IN SOUTHERN FRANCE WAS CONFISCATED BY THE FRENCH GOVERNMENT, AND AS SUCH I HAD TO CHANGE MY IDENTITY SO THAT MY INVESTMENT WILL NOT BE TRACED AND CONFISCATED . I HAVE DEPOSITED THE SUM EIGHTEEN MILLION UNITED STATE DOLLARS (US $18,000,000,00 .) WITH A SECURITY COMPANY, FOR SAFEKEEPING . THE FUNDS ARE SECURITY CODED TO PREVENT THEM FROM KNOWING THE CONTENT . WHAT I WANT YOU TO DO IS TO INDICATE YOUR INTEREST THAT YOU WILL ASSIST US BY RECEIVING THE MONEY ON OUR BEHALF.ACKNOWLEDGE THIS MESSAGE, SO THAT I CAN INTRODUCE YOU TO MY SON (KONGOLO) WHO HAS THE OUT MODALITIES FOR THE CLAIM OF THE SAID FUNDS . I WANT YOU TO ASSIST IN INVESTING THIS MONEY, BUT I WILL NOT WANT MY IDENTITY REVEALED . I WILL ALSO WANT TO BUY PROPERTIES AND STOCK IN MULTI-NATIONAL COMPANIES AND TO ENGAGE IN OTHER SAFE AND NON-SPECULATIVE INVESTMENTS . MAY I AT THIS POINT EMPHASISE THE HIGH LEVEL OF CONFIDENTIALITY, WHICH THIS BUSINESS DEMANDS, AND HOPE YOU WILL NOT BETRAY THE TRUST AND CONFIDENCE, WHICH I REPOSE IN YOU . IN CONCLUSION, IF YOU WANT TO ASSIST US, MY SON SHALL PUT YOU IN THE PICTURE OF THE BUSINESS, TELL YOU WHERE THE FUNDS ARE CURRENTLY BEING MAINTAINED AND ALSO DISCUSS OTHER MODALITIES INCLUDING REMUNERATIONFOR YOUR SERVICES . FOR THIS REASON KINDLY FURNISH US YOUR CONTACT INFORMATION, THAT IS YOUR PERSONAL TELEPHONE AND FAX NUMBER FOR CONFIDENTIAL PURPOSE.BEST REGARDS, MRS M. SESE SEKO\n",
      "Spam detection software, running on the system \"Roys-MacBook-Pro.local\",\n",
      "has identified this incoming email as possible spam.  The original\n",
      "message has been attached to this so you can view it or label\n",
      "similar future email.  If you have any questions, see\n",
      "the administrator of that system for details.\n",
      "\n",
      "Content preview:  DEAR FRIEND, I AM MRS. SESE-SEKO WIDOW OF LATE PRESIDENT MOBUTU\n",
      "SESE-SEKO OF ZAIRE? NOW KNOWN AS DEMOCRATIC REPUBLIC OF CONGO (DRC). I AM\n",
      "MOVED TO WRITE YOU THIS LETTER, THIS WAS IN CONFIDENCE CONSIDE [...]\n",
      "\n",
      "Content analysis details:   (5.9 points, 5.0 required)\n",
      "\n",
      "pts rule name              description\n",
      "---- ---------------------- --------------------------------------------------\n",
      "-0.0 NO_RECEIVED            Informational: message has no Received headers\n",
      "0.5 SUBJ_ALL_CAPS          Subject is all capitals\n",
      "-0.0 NO_RELAYS              Informational: message was not relayed via SMTP\n",
      "0.0 MILLION_USD            BODY: Talks about millions of dollars\n",
      "2.6 DEAR_FRIEND            BODY: Dear Friend? That's not very dear!\n",
      "0.0 LOTS_OF_MONEY          Huge... sums of money\n",
      "-0.0 T_SCC_BODY_TEXT_LINE   No description available.\n",
      "1.2 UPPERCASE_75_100       message body is 75-100% uppercase\n",
      "0.0 MONEY_FRAUD_8          Lots of money and very many fraud phrases\n",
      "1.7 ADVANCE_FEE_4_NEW_MONEY Advance Fee fraud and lots of money\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/spam_working_with.txt\", 'r') as f:\n",
    "    raw_text = f.read().split(\"\\n\\n\")\n",
    "    header, body = raw_text[0], raw_text[1]\n",
    "    body = nltk.word_tokenize(body)\n",
    "    poisoned_text = [w if w.lower() not in set(most_spammy_words[:200]) else poison_word(w)\n",
    "                 for w in body]\n",
    "    poisoned_text = TreebankWordDetokenizer().detokenize(body)\n",
    "    full_text = header + \"\\n\\n\" + poisoned_text\n",
    "    \n",
    "print(full_text)\n",
    "\n",
    "# spam_text = spam_text.lower()\n",
    "full_bytes = full_text.encode('utf-8')\n",
    "assassin = SpamAssassin(full_bytes)\n",
    "print(assassin.get_fulltext())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
