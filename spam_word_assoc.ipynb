{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nickhansen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from spamassassin_client import SpamAssassin\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 5000), (433, 2172), (347, 1891))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all of the formatted data\n",
    "enron_df, ling_df, sacorp_df = pd.read_csv('data/formattedData/enronFormatted.csv'), pd.read_csv('data/formattedData/lingFormatted.csv'), pd.read_csv('data/formattedData/SAcorpusFormatted.csv')\n",
    "\n",
    "enron_spam = enron_df[enron_df['label'] == 1]\n",
    "enron_ham = enron_df[enron_df['label'] == 0]\n",
    "\n",
    "ling_spam = ling_df[ling_df['label'] == 1]\n",
    "ling_ham = ling_df[ling_df['label'] == 0]\n",
    "\n",
    "sacorp_spam = sacorp_df[sacorp_df['label'] == 1]\n",
    "sacorp_ham = sacorp_df[sacorp_df['label'] == 0]\n",
    "\n",
    "(enron_spam.shape[0], enron_ham.shape[0]), (ling_spam.shape[0], ling_ham.shape[0]), (sacorp_spam.shape[0], sacorp_ham.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14843, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take 300 ham and 300 spam from each dataset\n",
    "sampleSize = 347\n",
    "\n",
    "enron_spam_sample = enron_spam.sample(5000)\n",
    "enron_ham_sample = enron_ham.sample(5000)\n",
    "\n",
    "ling_spam_sample = ling_spam.sample(433)\n",
    "ling_ham_sample = ling_ham.sample(2172)\n",
    "\n",
    "sacorp_spam_sample = sacorp_spam.sample(347)\n",
    "sacorp_ham_sample = sacorp_ham.sample(1891)\n",
    "\n",
    "# combine the datasets\n",
    "data = pd.concat([enron_spam_sample, enron_ham_sample, ling_spam_sample, ling_ham_sample, sacorp_spam_sample, sacorp_ham_sample])\n",
    "data = data.sample(frac=1).reset_index(drop=True) # shuffle the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header(text):\n",
    "    return text.split('\\n\\n', 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = list(zip(data['text'], data['label']))\n",
    "data_tuples = [(remove_header(text), label) for (text, label) in data_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "vocab = set()\n",
    "for text, label in data_tuples:\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        w_l = word.lower()\n",
    "        if w_l.isalpha() and word not in STOP_WORDS: # TODO: should also check if in stopwords?\n",
    "            vocab.add(w_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(text):\n",
    "    rec_words = [w.lower() for w in nltk.word_tokenize(text)]\n",
    "    features = {}\n",
    "    for w in rec_words:\n",
    "        if w in vocab:\n",
    "            features[w] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tuples = [(get_features(text), label) for (text, label) in data_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1388, 694)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitPoint = len(feature_tuples) // 3\n",
    "train, test = feature_tuples[splitPoint:], feature_tuples[:splitPoint]\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9265129682997119\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train)\n",
    "# now, it is tested on the test set and the accuracy reported\n",
    "print(\"Accuracy: \", nltk.classify.accuracy(classifier, test)) #nltk.classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                language = True                0 : 1      =     53.3 : 1.0\n",
      "                mailings = True                1 : 0      =     44.1 : 1.0\n",
      "                 amazing = True                1 : 0      =     28.8 : 1.0\n",
      "                  topics = True                0 : 1      =     27.2 : 1.0\n",
      "                   wrote = True                0 : 1      =     26.0 : 1.0\n",
      "                evidence = True                0 : 1      =     24.5 : 1.0\n",
      "                     ect = True                0 : 1      =     23.8 : 1.0\n",
      "                 science = True                0 : 1      =     23.8 : 1.0\n",
      "                     sep = True                0 : 1      =     23.1 : 1.0\n",
      "                   fresh = True                1 : 0      =     22.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features_in_list(classifier, n=10):\n",
    "    \"\"\"\n",
    "    Return a nested list of the \"most informative\" features \n",
    "    used by the classifier along with it's predominant labels\n",
    "    \"\"\"\n",
    "    cpdist = classifier._feature_probdist       # probability distribution for feature values given labels\n",
    "    feature_list = []\n",
    "    for (fname, fval) in classifier.most_informative_features(n):\n",
    "        def labelprob(l):\n",
    "            return cpdist[l, fname].prob(fval)\n",
    "        labels = sorted([l for l in classifier._labels if fval in cpdist[l, fname].samples()], \n",
    "                        key=labelprob)\n",
    "        feature_list.append([fname, labels[-1]])\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_features = [x for x in show_most_informative_features_in_list(classifier, n=500) if x[1] == 1]\n",
    "len(spam_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mailings',\n",
       " 'amazing',\n",
       " 'fresh',\n",
       " 'toll',\n",
       " 'postal',\n",
       " 'instructions',\n",
       " 'proven',\n",
       " 'advertise',\n",
       " 'removal',\n",
       " 'engines']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spammy_words = [x[0] for x in spam_features]\n",
    "spammy_words[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
